# !pip install wavenet_vocoder
# !pip install librosa
# !pip install tqdm
# !pip install seaborn
# !pip install tensorboardX
# !pip install docopt
# !pip install nnmnkwii
# !pip install tensorflow==1.3.0.
# !pip install lws==1.2

################################################################################

import os
import glob
import time
import json

import pandas as pd
import seaborn as sns
import numpy as np
from tqdm import tnrange, tqdm
import matplotlib.pyplot as plt

import torch
from torch.utils.data import Dataset, DataLoader
#from torchaudio import transforms

import librosa
import librosa.display
from librosa.feature import melspectrogram
import IPython.display as ipd


#from VCTKDataset import VCTKDataset
from wavenet_vocoder.hparams import hparams

plt.ion()   # interactive mode
plt.style.use(['seaborn-poster'])

assert hparams.name == "wavenet_vocoder"

print(hparams.hop_size)

################################################################################

def _normalize(S):
    return np.clip((S - hparams.min_level_db) / -hparams.min_level_db, 0, 1)

def pad_len(chunk, chunk_len):
    len_pad = 0
    if (chunk.shape[0] != chunk_len):
        len_pad = chunk_len - chunk.shape[0]
        chunk = librosa.util.fix_length(chunk, chunk_len)
    return chunk, len_pad

def convert_and_store_data(data_path='/root/dataset/LJSpeech-1.1/wavs/', out_dir="/root/dataset/ljspeech", sr=8000, sr_target=22050, chunk_len = 20480):
    print('Check if data exist...')
    if os.path.isfile(os.path.join(out_dir,'data.json')):
        print('Numpy chuncks yet exists.\nFinished!')
        return
    else:
        print('Data not found. Start conversion...')

    files = glob.glob(data_path+"*.wav")
    raw_samples = []
    target_samples = []
    Y = []
    X = []
    n_sample = 0

    for f in tqdm_notebook(files):
        sample_chunks = []
        sample_chunks_hat = []
        sample_chunks_mel = []
        sample_chunks_mel_hat = []

        sample, sr = librosa.core.load(f, sr=sr_target, mono=True)
        length = sample.shape[0]

        # Adjust length of sample, multiple of hop_size
        len_padds = 0
        for i in range(0, sample.shape[0], chunk_len):
            chunk = sample[i:i+chunk_len]
            chunk, len_pad = pad_len(chunk, chunk_len)
            len_padds += len_pad

            chunk_mel = _normalize(melspectrogram(chunk, sr=sr_target, n_fft=hparams.fft_size, n_mels=hparams.num_mels, hop_length=hparams.hop_size)).astype(np.float32)
            chunk_hat = librosa.core.resample(chunk, sr_target, sr)
            chunk_mel_hat = _normalize(melspectrogram(chunk_hat, sr=sr, n_fft=hparams.fft_size, n_mels=hparams.num_mels, hop_length=hparams.hop_size)).astype(np.float32)

            sample_chunks.append(chunk)
            sample_chunks_hat.append(chunk_hat)
            sample_chunks_mel.append(chunk_mel)
            sample_chunks_mel_hat.append(chunk_mel_hat)

            N = chunk_mel.shape[0]
            assert len(chunk) >= N * hparams.hop_size

            N_hat = chunk_mel_hat.shape[0]
            assert len(chunk_hat) >= N_hat * hparams.hop_size

        assert len(sample_chunks) == (sample.shape[0]+len_padds)/chunk_len


        raw_samples.append(sample_chunks)
        target_samples.append(sample_chunks_hat)
        Y.append(sample_chunks_mel)
        X.append(sample_chunks_mel_hat)
        n_sample += 1

    raw_samples = np.array(raw_samples)
    target_samples = np.array(target_samples)
    Y = np.array(Y)
    X = np.array(X)

    np.save(os.path.join(out_dir,'raw_samples.npy'), raw_samples, allow_pickle=False,)
    np.save(os.path.join(out_dir,'target_samples.npy'), target_samples, allow_pickle=False)
    np.save(os.path.join(out_dir,'target_mel.npy'), Y, allow_pickle=False)
    np.save(os.path.join(out_dir,'raw_mel.npy'), X, allow_pickle=False)

    data = {
        "n_sample" : n_sample,
        "sample_rate" : sr,
        "target_sample_rate" : target_sr,
        "chunk_len" : chunk_len,
        "timestamp" : time.time()
    }
    with open(os.path.join(out_dir,'data.json'), 'w') as f:
        json.dump(data, f)
    print('Finished!')

def load_stored_data(data_path='/root/dataset/ljspeech'):
    raw_samples = np.load(os.path.join(data_path,'raw_samples.npy')).astype(np.float32)
    raw_mel = np.load(os.path.join(data_path,'raw_mel.npy')).astype(np.float32)
    target_samples = np.load(os.path.join(data_path,'target_samples.npy')).astype(np.float32)
    target_mel = np.load(os.path.join(data_path,'target_mel.npy')).astype(np.float32)

    with open(os.path.join(data_path,'data.json')) as f:
        data = json.load(f)

    return (raw_samples, raw_mel, target_samples, target_mel, data['sr'], data['target_sr'], data['chunck_len'], data['n_samples'])


convert()
