{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_train_from_local.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CCVSdf8XP-r4","colab_type":"code","outputId":"449640e5-4d9a-4c63-a4a6-eaa441805cac","executionInfo":{"status":"ok","timestamp":1563360804753,"user_tz":-120,"elapsed":23055,"user":{"displayName":"Matteo Barato","photoUrl":"https://lh6.googleusercontent.com/-inD3iOjb_V4/AAAAAAAAAAI/AAAAAAAAAiE/fpz5t3AKHro/s64/photo.jpg","userId":"11150295013903053945"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Run this cell to mount your Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QwPxp1IkQII_","colab_type":"code","outputId":"2a2d14ad-2c14-4909-da92-3ed37521c576","executionInfo":{"status":"ok","timestamp":1563360828285,"user_tz":-120,"elapsed":46572,"user":{"displayName":"Matteo Barato","photoUrl":"https://lh6.googleusercontent.com/-inD3iOjb_V4/AAAAAAAAAAI/AAAAAAAAAiE/fpz5t3AKHro/s64/photo.jpg","userId":"11150295013903053945"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["PRJ_DIR = '/content/drive/My Drive/Colab Notebooks/Waven_up'\n","\n","import sys\n","sys.path.append(PRJ_DIR)\n","\n","import os\n","import datetime\n","\n","import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","!pip install tensorboardcolab\n","from tensorboardcolab import TensorBoardColab\n","tb = TensorBoardColab()\n","\n","\n","from LJSpeechDataset import LJSpeechDataset\n","from hparams import hparams, Struct\n","from model import Generator as AEUpsampler\n","\n","plt.ion()   # interactive mode\n","plt.style.use(['seaborn-poster'])\n","\n","torch.set_num_threads(4)\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","print(device)\n","\n","seed=42\n","np.random.seed(seed)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://d203a360.ngrok.io\n","wavenet_vocoder\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jJG0qCQ5QJn0","colab_type":"code","colab":{}},"source":["from math import ceil\n","\n","def pad_seq(x, base=32):\n","    len_out = int(base * ceil(float(x.shape[0])/base))\n","    len_pad = len_out - x.shape[0]\n","    assert len_pad >= 0\n","    return np.pad(x, ((0,len_pad),(0,0)), 'constant'), len_pad\n","  \n","def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n","    torch.save(state, filename)\n","    print(\"## checkpoin {} saved!\".format(filename))\n","    if is_best:\n","        shutil.copyfile(filename, 'model_best.pth.tar')\n","        \n","def load_checkpoint(model, optimizer, filename='checkpoint.pth.tar'):\n","        if os.path.isfile(filename):\n","            print(\"=> loading checkpoint '{}'\".format(filename))\n","            checkpoint = torch.load(filename)\n","            epoch = checkpoint['epoch']\n","            model.load_state_dict(checkpoint['state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer'])\n","            print(\"=> loaded checkpoint '{}' (epoch {})\"\n","                  .format(filename, checkpoint['epoch']))\n","        else:\n","            print(\"=> no checkpoint found at '{}'\".format(filename)) \n","        return model, optimizer, epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_evdBjZiQOIZ","colab_type":"code","outputId":"81ca1013-fa74-49b8-9bed-06af6d4d6d8a","executionInfo":{"status":"ok","timestamp":1563360832860,"user_tz":-120,"elapsed":51130,"user":{"displayName":"Matteo Barato","photoUrl":"https://lh6.googleusercontent.com/-inD3iOjb_V4/AAAAAAAAAAI/AAAAAAAAAiE/fpz5t3AKHro/s64/photo.jpg","userId":"11150295013903053945"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["%%time\n","\n","args = Struct(**{\n","    'checkpoint_dir': PRJ_DIR + '/checkpoints/',\n","    'checkpoint_path' : PRJ_DIR + '/checkpoints/checkpoint_4000_1600_ep51_31.pth.tar',\n","    'dataset_dir': PRJ_DIR+'/dataset/ljspeech4000_16000'\n","})\n","\n","ljspeech = LJSpeechDataset(args.dataset_dir)\n","model = AEUpsampler(32,0,512,32).to(device)\n","\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","start_epoch = 0\n","\n","# Load model from last checkpoint\n","if (args.checkpoint_path):\n","  model, optimizer, start_epoch = load_checkpoint(model, optimizer, args.checkpoint_path)  \n","    \n","inputs, labels = ljspeech.__getitem__(0)\n","\n","x, _ = pad_seq(np.array(inputs[0]).T)\n","y, _ = pad_seq(np.array(labels[0]).T)\n","                    \n","x = torch.from_numpy(x[np.newaxis, :, :]).to(device)\n","y = torch.from_numpy(y[np.newaxis, np.newaxis, :, :]).to(device)\n","\n","print('-'*100)\n","print('X SHAPE, Y SHAPE')\n","print(x.shape, y.shape)\n","print('-'*100)\n","print('MEL_OUT SHAPE, MEL_OUT_POST SHAPE, CODES SHAPE')\n","\n","mel_outputs, mel_outputs_postnet, codes = model(x)\n","print(mel_outputs.shape, mel_outputs_postnet.shape, codes.shape)\n","print('-'*100)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["=> loading checkpoint '/content/drive/My Drive/Colab Notebooks/Waven_up/checkpoints/checkpoint_4000_1600_ep51_31.pth.tar'\n","=> loaded checkpoint '/content/drive/My Drive/Colab Notebooks/Waven_up/checkpoints/checkpoint_4000_1600_ep51_31.pth.tar' (epoch 52)\n","----------------------------------------------------------------------------------------------------\n","X SHAPE, Y SHAPE\n","torch.Size([1, 32, 80]) torch.Size([1, 1, 128, 80])\n","----------------------------------------------------------------------------------------------------\n","MEL_OUT SHAPE, MEL_OUT_POST SHAPE, CODES SHAPE\n","torch.Size([1, 1, 128, 80]) torch.Size([1, 1, 128, 80]) torch.Size([1, 64])\n","----------------------------------------------------------------------------------------------------\n","CPU times: user 3 s, sys: 1.25 s, total: 4.25 s\n","Wall time: 4.63 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GPqvllpJQUfY","colab_type":"code","outputId":"71a1c6a8-018a-4446-9357-46ef9c7ace5d","colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["%%time\n","\n","train_samples_index, testval_samples_index = ljspeech.getRandomSamplesIndex(seed, 0.4)\n","\n","testval_samples_index = np.split(testval_samples_index, 2)\n","train_samples_index = train_samples_index.astype(np.int32)\n","val_samples_index = testval_samples_index[0].astype(np.int32)\n","test_samples_index = testval_samples_index[1].astype(np.int32)\n","\n","print('TRAIN n_samples {}'.format(len(train_samples_index)))\n","print('VAL n_samples {}'.format(len(val_samples_index)))\n","\n","print(train_samples_index.shape, val_samples_index.shape, test_samples_index.shape)\n","\n","for epoch in tqdm(range(10)):  # loop over the dataset multiple times\n","  epoch = start_epoch + epoch\n","  running_loss = 0.0\n","  batch_running_loss = 0.0\n","  val_running_loss = 0.0\n","  \n","  ### TRAIN ###\n","  model = model.train()\n","  for i_step, i in enumerate(train_samples_index,0):\n","    # get the inputs; data is a list of [inputs, labels]\n","\n","    inputs, labels = ljspeech.__getitem__(i)\n","    \n","    for j,_ in enumerate(inputs):  \n","      x, _ = pad_seq(np.array(inputs[j]).T)\n","      y, _ = pad_seq(np.array(labels[j]).T)\n","                    \n","      x = torch.from_numpy(x[np.newaxis, :, :]).to(device)\n","      y = torch.from_numpy(y[np.newaxis, np.newaxis, :, :]).to(device)\n","\n","      # zero the parameter gradients\n","      optimizer.zero_grad()\n","\n","      # forward + backward + optimize\n","      mel_outputs, mel_outputs_postnet, codes = model(x)\n","      loss = criterion(mel_outputs_postnet, y)\n","      loss.backward()\n","      optimizer.step()      \n","\n","      # print statistics\n","      running_loss += loss.item()\n","      batch_running_loss += loss.item()\n","      \n","    # print every 1000 mini-batches\n","    n_mb = 1000\n","    if (i_step % n_mb == (n_mb-1)):\n","      print('[%d, %5d] loss: %.3f' % (epoch + 1, i_step + 1, batch_running_loss/n_mb))  \n","      batch_running_loss = 0\n","      \n","  ### VALIDATION ###\n","  model = model.eval()\n","  val_running_loss = 0\n","  for i_step, i in enumerate(val_samples_index[:100]):\n","    # get the inputs; data is a list of [inputs, labels]\n","    inputs, labels = ljspeech.__getitem__(i)\n","        \n","    for j,_ in enumerate(inputs):  \n","      x, _ = pad_seq(np.array(inputs[j]).T)\n","      y, _ = pad_seq(np.array(labels[j]).T)\n","      \n","      x = torch.from_numpy(x[np.newaxis, :, :]).to(device)\n","      y = torch.from_numpy(y[np.newaxis, np.newaxis, :, :]).to(device)\n","\n","      # forward + backward + optimize\n","      mel_outputs, mel_outputs_postnet, codes = model(x)\n","      loss = criterion(mel_outputs_postnet, y)    \n","\n","      # print statistics\n","      val_running_loss += loss.item() \n","  print('-----> [%d, %5d] acc_loss: %.3f' % (epoch + 1, i_step + 1, running_loss/len(val_samples_index)))          \n","      \n","      \n","      \n","  tb.save_value('Train Loss', 'train_loss', epoch+1, running_loss/len(train_samples_index))\n","  tb.save_value('Acc Loss', 'acc_loss', epoch+1, val_running_loss/len(val_samples_index))\n","  \n","  running_loss = 0\n","  val_running_loss = 0\n","  \n","  save_checkpoint({\n","            'epoch': epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'optimizer' : optimizer.state_dict(),\n","        }, False, filename=os.path.join(args.checkpoint_dir,'checkpoint_4000_1600_ep{}_31.pth.tar'.format(epoch)) )\n","\n","print('Finished Training')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["TRAIN n_samples 7729\n","VAL n_samples 2620\n","(7729,) (2620,) (2620,)\n","[53,  1000] loss: 0.041\n","[53,  2000] loss: 0.039\n","[53,  3000] loss: 0.037\n","[53,  4000] loss: 0.037\n","[53,  5000] loss: 0.037\n","[53,  6000] loss: 0.037\n","[53,  7000] loss: 0.036\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cJz5iwRHQWMM","colab_type":"code","colab":{}},"source":["%%time\n","\n","inputs, labels = ljspeech.__getitem__(0)\n","\n","for j,_ in enumerate(inputs):  \n","      x, _ = pad_seq(np.array(inputs[j]).T)\n","      y, _ = pad_seq(np.array(labels[j]).T)\n","                    \n","      x = torch.from_numpy(x[np.newaxis, :, :]).to(device)\n","      y = torch.from_numpy(y[np.newaxis, np.newaxis, :, :]).to(device)\n","      \n","      with torch.no_grad():\n","        mel_outputs, mel_outputs_postnet, codes = model(x)\n","        loss = criterion(mel_outputs_postnet, y) \n","        print(\"loss: {}\".format(loss))\n","        \n","      print(mel_outputs, mel_outputs_postnet)\n","      mel_outputs, mel_outputs_postnet = mel_outputs.cpu().numpy(), mel_outputs_postnet.cpu().numpy()\n","      np.save(PRJ_DIR+'/dataset/mel_out_{}__acc_loss{}.npy'.format(j, loss*100), mel_outputs)\n","      np.save(PRJ_DIR+'/dataset/mel_out_pos_{}_acc_loss{}.npy'.format(j, loss*100), mel_outputs_postnet)      "],"execution_count":0,"outputs":[]}]}